{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhussn/SecSplitLLM/blob/main/SecSplitLLM/notebooks/benchmarks/gpt-2/Benchmark_GPT2_SST_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0BCHpMtIxJT"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch] accelerate -U\n",
        "!pip install datasets evaluate\n",
        "!pip install trl\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21XyIM0y3U0F"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeSowkCBIybh"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from transformers import TrainerCallback\n",
        "import torch # Import torch for GPU memory\n",
        "import time  # Import time for tracking time\n",
        "\n",
        "class CSVLoggerCallback(TrainerCallback):\n",
        "    def __init__(self, csv_filepath, model_name, run_name):\n",
        "        self.csv_filepath = csv_filepath\n",
        "        self.csv_file = open(self.csv_filepath, 'a', newline='')\n",
        "        file_exists = os.path.exists(self.csv_filepath)\n",
        "        self.writer = csv.writer(self.csv_file)\n",
        "        # Write header only if the file is new or empty\n",
        "        if not file_exists or os.path.getsize(self.csv_filepath) == 0:\n",
        "             self.writer.writerow(['model', 'run_name', 'epoch', 'train_loss', 'val_loss', 'eval_accuracy', 'gpu_memory_mb', 'epoch_duration_seconds'])\n",
        "        self.model_name = model_name # Store the model name\n",
        "        self.run_name = run_name # Store the run name\n",
        "        # Updated header to include GPU memory and training time\n",
        "\n",
        "        self.epoch_start_time = None\n",
        "        self.peak_gpu_memory_mb = 0\n",
        "        self.logged_epochs = set() # Keep track of epochs already logged\n",
        "\n",
        "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
        "        self.epoch_start_time = time.time()\n",
        "        # Reset peak memory at the start of each epoch\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.reset_peak_memory_stats()\n",
        "            self.peak_gpu_memory_mb = 0 # Reset the stored peak memory\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None:\n",
        "            epoch = logs.get('epoch')\n",
        "            train_loss = logs.get('loss') # Assuming 'loss' is the key for training loss\n",
        "            eval_loss = logs.get('eval_loss')\n",
        "            eval_accuracy = logs.get('eval_accuracy')\n",
        "\n",
        "            # Capture current GPU memory usage\n",
        "            if torch.cuda.is_available():\n",
        "                current_gpu_memory_allocated = torch.cuda.memory_allocated()\n",
        "                current_gpu_memory_cached = torch.cuda.memory_cached()\n",
        "                # Using allocated memory for a more direct measure of usage\n",
        "                gpu_memory_mb = (current_gpu_memory_allocated / 1024 / 1024)\n",
        "                 # Update peak memory if current is higher\n",
        "                if gpu_memory_mb > self.peak_gpu_memory_mb:\n",
        "                    self.peak_gpu_memory_mb = gpu_memory_mb\n",
        "            else:\n",
        "                gpu_memory_mb = 0\n",
        "\n",
        "            # Log training info with current memory usage\n",
        "            if train_loss is not None and epoch is not None:\n",
        "                self.last_train_loss = train_loss\n",
        "                # Log training loss, leaving eval columns empty\n",
        "                self.writer.writerow([self.model_name, self.run_name, f'{epoch:.2f}', train_loss, '', '', gpu_memory_mb, ''])\n",
        "\n",
        "            # Log evaluation info at the end of an epoch\n",
        "            # This part is triggered when eval_strategy=\"epoch\"\n",
        "            if eval_loss is not None and eval_accuracy is not None and epoch is not None:\n",
        "              int_epoch = int(epoch)\n",
        "              if int_epoch not in self.logged_epochs:\n",
        "                  epoch_end_time = time.time()\n",
        "                  epoch_duration = epoch_end_time - self.epoch_start_time if self.epoch_start_time else 0\n",
        "\n",
        "                # Log eval metrics, training loss is not applicable here\n",
        "                # Using the peak memory recorded during the epoch\n",
        "                  self.writer.writerow([self.model_name, self.run_name, int(epoch), self.last_train_loss, eval_loss, eval_accuracy, self.peak_gpu_memory_mb, epoch_duration])\n",
        "                  self.logged_epochs.add(int_epoch) # Add the epoch to the set of logged epochs\n",
        "\n",
        "        self.csv_file.flush()\n",
        "\n",
        "    def __del__(self):\n",
        "        if self.csv_file:\n",
        "            self.csv_file.close()\n",
        "\n",
        "\n",
        "%load_ext cudf.pandas\n",
        "import pandas as pd # Imports the panda library from huggin face to load and visualize the dataset\n",
        "df = pd.read_parquet(\"hf://datasets/stanfordnlp/imdb/plain_text/train-00000-of-00001.parquet\")\n",
        "df_sample = df.sample(frac=0.012)\n",
        "print(df_sample)\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_PROJECT\"] = \"gpt2-classification\"\n",
        "os.environ[\"WANDB_WATCH\"] = \"all\"\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "# Convert the pandas DataFrame to a Dataset\n",
        "dataset = Dataset.from_pandas(df_sample)\n",
        "\n",
        "# Load the GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token # GPT-2 doesn't have a padding token by default\n",
        "\n",
        "# Tokenize the text\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Split into train and validation sets\n",
        "train_test_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split[\"train\"]\n",
        "eval_dataset = train_test_split[\"test\"]\n",
        "\n",
        "from transformers import GPT2ForSequenceClassification\n",
        "\n",
        "# Define the number of labels (positive/negative)\n",
        "num_labels = 2\n",
        "\n",
        "# Load GPT-2 with a sequence classification head\n",
        "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=num_labels)\n",
        "model.config.pad_token_id = tokenizer.pad_token_id # Set padding token id for the model\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "    # Define evaluation metric\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",  # Output directory\n",
        "        report_to=\"wandb\",\n",
        "        run_name=\"gpt2_classification_11_1\",  # Run name\n",
        "        num_train_epochs=2,  # Number of training epochs\n",
        "        per_device_train_batch_size=8,  # Batch size per device during training\n",
        "        per_device_eval_batch_size=8,   # Batch size for evaluation\n",
        "        warmup_steps=500,  # Number of warmup steps for learning rate scheduler\n",
        "        weight_decay=0.01,  # Strength of weight decay\n",
        "        logging_dir=\"./logs\",  # Directory for storing logs\n",
        "        logging_steps=15,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "    )\n",
        "# Get model_name and_run to pass it to the logger\n",
        "model_name = model.config._name_or_path if hasattr(model, 'config') and hasattr(model.config, '_name_or_path') else \"unknown_model\"\n",
        "run_name = training_args.run_name\n",
        "\n",
        "# Create a CSVLoggerCallback instance\n",
        "csv_logger_callback = CSVLoggerCallback('./trainingGPT2_log.csv', model_name, run_name)\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "        model=model,  # The model to train\n",
        "        args=training_args,  # The training arguments\n",
        "        train_dataset=train_dataset,  # The training dataset\n",
        "        eval_dataset=eval_dataset,  # The evaluation dataset\n",
        "        compute_metrics=compute_metrics, # The function to compute metrics\n",
        "        callbacks=[csv_logger_callback],\n",
        "    )\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print(f\"Validation Loss: {results['eval_loss']}\")\n",
        "\n",
        "model.save_pretrained('fine-tuned-gpt2')\n",
        "tokenizer.save_pretrained('fine-tuned-gpt2')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}